{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lP6JLo1tGNBg"
   },
   "source": [
    "# Artificial Neural Network (ANN)\n",
    "\n",
    "In this example, we import an .csv file that contains a bank's customer information. The ANN feeds on customer info and then computes this to the outcome (whether the customer decides to leave within 6 months or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWZyYmS_UE_L"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxkJoQBkUIHC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZaTwK7ojXr2F",
    "outputId": "0b27a96d-d11a-43e8-ab4b-87c1f01896fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1E0Q3aoKUCRX"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKWAkFVGUU0Z"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXUkhkMfU4wq"
   },
   "outputs": [],
   "source": [
    "# A data set that describes customer information of a bank\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "#take column no.3 to second last column\n",
    "X = dataset.iloc[:,3:-1].values\n",
    "#take the last column\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "VYP9cQTWbzuI",
    "outputId": "797e7a64-9bac-436a-8c9c-94437e5e7587"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 'Female' ... 1 1 101348.88]\n",
      " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
      " [502 'France' 'Female' ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 'Female' ... 0 1 42085.58]\n",
      " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
      " [792 'France' 'Female' ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "38vKGE6Nb2RR",
    "outputId": "a815e42a-e0dd-4cb5-ab97-b17ead98fbc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N6bQ0UgSU-NJ"
   },
   "source": [
    "### Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "le5MJreAbW52"
   },
   "source": [
    "Categorial data consist of X\\[:,1](Country) and X\\[:,2](Gender)\n",
    "\n",
    "(1)Label Encoding the \"Gender\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxVKWXxLbczC"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Gender\" column is now encoded by 0(female) and 1(male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "-M1KboxFb6OO",
    "outputId": "e2b8c7e8-0cbc-4cdf-f4eb-7f0853a00b88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 0 ... 1 1 101348.88]\n",
      " [608 'Spain' 0 ... 0 1 112542.58]\n",
      " [502 'France' 0 ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 0 ... 0 1 42085.58]\n",
      " [772 'Germany' 1 ... 1 0 92888.52]\n",
      " [792 'France' 0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CUxGZezpbMcb"
   },
   "source": [
    "(2)One Hot Encoding the \"Geography\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMXC8-KMVirw"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 'France' is coded as \\[0, 0, 1], Spain is coded as \\[0,0,1] and Germany \\[0,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "ZcxwEon-b8nV",
    "outputId": "23a98af4-5e33-4b26-c27b-f06e3c5d2baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
      " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
      " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
      " ...\n",
      " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
      " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
      " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHol938cW8zd"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-TDt0Y_XEfc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size for training data 8000 \n",
      "Size for test data 2000\n",
      "Note: X arranges as [0,0,1] country code, credit score,gender ... savings\n",
      "X[0] [0.0 0.0 1.0 667 0 34 5 0.0 2 1 0 163830.64]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "print('Size for training data',len(X_train),'\\nSize for test data',len(X_test))\n",
    "print('Note: X arranges as [0,0,1] country code, credit score,gender ... savings')\n",
    "print('X[0]',X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RE_FcHyfV3TQ"
   },
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ViCrE00rV8Sk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.01460667 -0.5698444   1.74309049  0.16958176 -1.09168714 -0.46460796\n",
      "  0.00666099 -1.21571749  0.8095029   0.64259497 -1.03227043  1.10643166]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zfEzkRVXIwF"
   },
   "source": [
    "## Part 2 - Building the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvdeScabXtlB"
   },
   "source": [
    "### Initializing the ANN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dtrScHxXQox"
   },
   "outputs": [],
   "source": [
    "#As a sequence of layers\n",
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rP6urV6SX7kS"
   },
   "source": [
    "### Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bppGycBXYCQr"
   },
   "outputs": [],
   "source": [
    "# 6 hidden neurons in the first hidden layer\n",
    "# unfortunately no rule of thumb with the number of choice\n",
    "# activation function being rectifier(linear)\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BELWAc_8YJze"
   },
   "source": [
    "### Adding the second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JneR0u0sYRTd"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyNEe6RXYcU4"
   },
   "source": [
    "### Adding the output layer\n",
    "one neuron (i.e. one final output) As we only wants to know whether the customer decides to stay or not.\n",
    "Sigmoid  function(See below) can also give the probablity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-5,5,0.1)\n",
    "y = np.exp(x)/(np.exp(x)+1)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3x41RBYfvY"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JT4u2S1_Y4WG"
   },
   "source": [
    "## Part 3 - Training the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GWlJChhY_ZI"
   },
   "source": [
    "### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG3RrwDXZEaS"
   },
   "outputs": [],
   "source": [
    "# adam optimizer: guess gredient descent\n",
    "#loss function: weighted difference between model and results\n",
    "#evaluation matrics = accuracy\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QR_G5u7ZLSM"
   },
   "source": [
    "### Training the ANN on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nHZ-LKv_ZRb3",
    "outputId": "718cc4b0-b5aa-40f0-9b20-d3d31730a531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 1ms/step - loss: 0.6045 - accuracy: 0.7261\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.8060\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4323 - accuracy: 0.8191\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4211 - accuracy: 0.8254\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4130 - accuracy: 0.8280\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4047 - accuracy: 0.8331\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3960 - accuracy: 0.8367\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3868 - accuracy: 0.8396\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3788 - accuracy: 0.8449\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8497\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8540\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3622 - accuracy: 0.8540\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3588 - accuracy: 0.8555\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3558 - accuracy: 0.8558\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3535 - accuracy: 0.8565\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8575\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3496 - accuracy: 0.8572\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3481 - accuracy: 0.8572\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3473 - accuracy: 0.8570\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3460 - accuracy: 0.8577\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3456 - accuracy: 0.8566\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.8583\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3447 - accuracy: 0.8584\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8581\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3433 - accuracy: 0.8577\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3433 - accuracy: 0.8591\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 0.8594\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8585\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8586\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3422 - accuracy: 0.8589\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3423 - accuracy: 0.8587\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3414 - accuracy: 0.8593\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3412 - accuracy: 0.8583\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3417 - accuracy: 0.8595\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.8595\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3410 - accuracy: 0.8602\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3409 - accuracy: 0.8604\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3403 - accuracy: 0.8586\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3411 - accuracy: 0.8604\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.8590\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8597\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3395 - accuracy: 0.8608\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3395 - accuracy: 0.8599\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3395 - accuracy: 0.8595\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8586\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3388 - accuracy: 0.8630\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3390 - accuracy: 0.8619\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8610\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8601\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3383 - accuracy: 0.8616\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8599\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.8615\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8615\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.8618\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3374 - accuracy: 0.8622\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.8601\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8614\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8616\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8640\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8621\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8619\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8629\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8608\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8627\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8614\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8619\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8618\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8622\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8618\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8619\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8631\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8639\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8618\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8621\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8634\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8615\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8624\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8621\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8627\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8640\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8626\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8630\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8627\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3332 - accuracy: 0.8625\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8635\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8620\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8625\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8612\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8622\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8618\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3326 - accuracy: 0.8636\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3330 - accuracy: 0.8627\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8644\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8640\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8622\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8641\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8626\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8626\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8643\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc8f4ddaa60>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch_size: No.of trainning data that are grouped together (default 32)\n",
    "#epoch: training iteration\n",
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJj5k2MxZga3"
   },
   "source": [
    "## Part 4 - Making the predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84QFoqGYeXHL"
   },
   "source": [
    "### Predicting the result of a single observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CGRo3eacgDdC"
   },
   "source": [
    "**Homework**\n",
    "\n",
    "Use our ANN model to predict if the customer with the following informations will leave the bank: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Geography: France #CODE [1,0,0]\n",
    "\n",
    "Credit Score: 600\n",
    "\n",
    "Gender: Male #[1]\n",
    "\n",
    "Age: 40 years old\n",
    "\n",
    "Tenure: 3 years\n",
    "\n",
    "Balance: \\$ 60000\n",
    "\n",
    "Number of Products: 2\n",
    "\n",
    "Does this customer have a credit card ? Yes #[1]\n",
    "\n",
    "Is this customer an Active Member: Yes #[1]\n",
    "\n",
    "Estimated Salary: \\$ 50000\n",
    "\n",
    "So, should we say goodbye to that customer ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZhU1LTgPg-kH"
   },
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2d8IoCCkeWGL",
    "outputId": "957f3970-e197-4c3b-a150-7f69dc567f5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]]\n"
     ]
    }
   ],
   "source": [
    "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]]))>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wGjx94g2n7OV"
   },
   "source": [
    "Therefore, our ANN model predicts that this customer stays in the bank!\n",
    "\n",
    "**Important note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.\n",
    "\n",
    "**Important note 2:** Notice also that the \"France\" country was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, \"France\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7yx47jPZt11"
   },
   "source": [
    "### Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "nIyEeQdRZwgs",
    "outputId": "82330ba8-9bdc-4fd1-d3cf-b6d78ee7c2a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "#vectoration of y_pred and real results\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0oyfLWoaEGw"
   },
   "source": [
    "### Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ci6K_r6LaF6P",
    "outputId": "4d854e9e-22d5-432f-f6e5-a102fe3ae0bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1522   73]\n",
      " [ 202  203]]\n",
      "0.8625 0.8625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "#ac = (cm[0,0]+ cm[1,1])/No.tests\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "print(cm, ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "artificial_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
